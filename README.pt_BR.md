<br><br>

\[[ğŸ‡§ğŸ‡· PortuguÃªs](README.pt_BR.md)\] \[**[ğŸ‡¬ğŸ‡§ English](README.md)**\]


<br><br>


# 15- [Data Mining]()  / [Project 3 â€“ Clustering Algorithms Exploration and Comparison]() - K-Means - Mean-Shift - Dbscan




<!-- ======================================= Start DEFAULT HEADER ===========================================  -->

<br><br>


[**Institution:**]() Pontifical Catholic University of SÃ£o Paulo (PUC-SP)  
[**School:**]() Faculty of Interdisciplinary Studies  
[**Program:**]() Humanistic AI and Data Science
[**Semester:**]() 2nd Semester 2025  
Professor:  [***Professor Doctor in Mathematics Daniel Rodrigues da Silva***](https://www.linkedin.com/in/daniel-rodrigues-048654a5/)

<br><br>

#### <p align="center"> [![Sponsor Quantum Software Development](https://img.shields.io/badge/Sponsor-Quantum%20Software%20Development-brightgreen?logo=GitHub)](https://github.com/sponsors/Quantum-Software-Development)


<br><br>

<!--Confidentiality statement -->

#

<br><br><br>

> [!IMPORTANT]
> 
> âš ï¸ Heads Up
>
> * Projects and deliverables may be made [publicly available]() whenever possible.
> * The course emphasizes [**practical, hands-on experience**]() with real datasets to simulate professional consulting scenarios in the fields of **Data Analysis and Data Mining** for partner organizations and institutions affiliated with the university.
> * All activities comply with the [**academic and ethical guidelines of PUC-SP**]().
> * Any content not authorized for public disclosure will remain [**confidential**]() and securely stored in [private repositories]().  
>


<br><br>

#

<!--END-->




<br><br><br><br>



<!-- PUC HEADER GIF
<p align="center">
  <img src="https://github.com/user-attachments/assets/0d6324da-9468-455e-b8d1-2cce8bb63b06" />
-->


<!-- video presentation -->


##### ğŸ¶ Prelude Suite no.1 (J. S. Bach) - [Sound Design Remix]()

https://github.com/user-attachments/assets/4ccd316b-74a1-4bae-9bc7-1c705be80498

####  ğŸ“º For better resolution, watch the video on [YouTube.](https://youtu.be/_ytC6S4oDbM)


<br><br>


> [!TIP]
> 
>  This repository is a review of the Statistics course from the undergraduate program Humanities, AI and Data Science at PUC-SP.
>
> ### â˜ **Access Data Mining [Main Repository](https://github.com/Quantum-Software-Development/1-Main_DataMining_Repository)**
>
>


<!-- =======================================END DEFAULT HEADER ===========================================  -->


<br><br><br>


## SumÃ¡rio

1. [VisÃ£o Geral do Projeto](#project-overview)
2. [O que tem neste repositÃ³rio](#whats-in-this-repo)
3. [InÃ­cio RÃ¡pido (executar o cÃ³digo)](#quick-start-run-the-code)
4. [ExplicaÃ§Ã£o Passo a Passo](#step-by-step-explanation-kid-friendly)
5. [CÃ³digo Passo a Passo](#data-cleaning--preprocessing)
6. [Algoritmos usados (K-Means, Mean-Shift, DBSCAN)](#algorithms-used-k-means-mean-shift-dbscan)
7. [Como escolhemos o eps do DBSCAN (grÃ¡fico K-distÃ¢ncia)](#how-we-chose-dbscan-eps-k-distance-graph)
8. [VisualizaÃ§Ã£o](#visualization--style-dark--turquoise)
9. [Resumo dos resultados & interpretaÃ§Ã£o](#results-summary--interpretation)
10. [PrÃ³ximos passos & sugestÃµes](#next-steps--suggestions)
    11 [Requisitos & ambiente](#requirements--environment)
11. [ReferÃªncias](#references)
12. [LicenÃ§a & crÃ©ditos](#license--credits)

<br><br>



## 1. [VisÃ£o Geral do Projeto]()

Este projeto carrega um dataset CSV (`Dados-Grupo4.csv`), inspeciona e limpa os dados, aplica normalizaÃ§Ã£o (feature scaling) e compara trÃªs algoritmos de clusterizaÃ§Ã£o: **K-Means, Mean-Shift e DBSCAN**. Inclui grÃ¡ficos em estilo turquesa escuro e explicaÃ§Ãµes claras para ajudar qualquer pessoa a entender o fluxo de trabalho e os resultados.


<br><br>

## 2. [O que tem neste RepositÃ³rio]()

* `Dados-Grupo4.csv` â€” arquivo principal do dataset.
* `notebook.ipynb` ou `run_clustering.py` â€” cÃ³digo principal responsÃ¡vel por carregar, limpar, clusterizar e plotar.
* `README.md` â€” esta documentaÃ§Ã£o.
* `requirements.txt` â€” lista de pacotes Python necessÃ¡rios.

<br><br>


## 3. [InÃ­cio RÃ¡pido (executar o cÃ³digo)]()

[3.1]()- Abra o Google Colab ou seu ambiente Python local.

<br>

[3.2]()- FaÃ§a o upload de `Dados-Grupo4.csv` para a pasta de trabalho.

<br>

[3.3]()- Instale as dependÃªncias:

<br>

```bash
pip install -r requirements.txt
```

<br>

[3.4]()- Execute o `notebook.ipynb` cÃ©lula por cÃ©lula ou rode:

<br>

```bash
python run_clustering.py
```

<br>


[3.5]()- **Exemplo de `requirements.txt`:**

<br>

```
pandas
numpy
matplotlib
seaborn
scikit-learn
```

<br><br>

## 4. [ExplicaÃ§Ã£o passo a passo]()

* Abrimos a tabela (CSV) â€” como abrir uma planilha.
* Contamos quantas linhas (linhas) e colunas (tipos de informaÃ§Ã£o) ela tem.
* Observamos nÃºmeros bÃ¡sicos: mÃ©dias, menores, maiores â€” ajuda a entender os dados.
* Removemos qualquer coluna extra chamada "Unnamed: 0", se existir.
* Se algumas cÃ©lulas estiverem vazias, preenchemos com o valor mais comum (moda).
* Se duas linhas forem idÃªnticas, excluÃ­mos as duplicatas.
* Escalonamos os nÃºmeros para que valores grandes nÃ£o dominem os padrÃµes.
* Usamos trÃªs mÃ©todos para agrupar pontos (K-Means, Mean-Shift, DBSCAN).
* Desenhamos os grupos como imagens com fundo escuro e cor turquesa.
* Comparamos os resultados e explicamos o que cada mÃ©todo descobriu.

<br><br>

## 5. [CÃ³digo Passo a Passo]()

Etapas tÃ­picas do cÃ³digo jÃ¡ estÃ£o **[aqui](https://github.com/Quantum-Software-Development/15-DataMining_Project_3_-Clustering_Comparison_KMeans_MeanShift_DBSCAN/blob/91ce4685c925253a2d054c9f89ebe16f00d27050/code/Project_3__Clustering_Comparison_KMeans_MeanShift_DBSCAN.ipynb)** no repositÃ³rio):

<br><br>

## 5.1 - [Ambiente & carregamento dos dados]()

[***O que faz***](): importa bibliotecas, define tema escuro e paleta turquesa, carrega o CSV e imprime o formato (shape).

<br>

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Configura matplotlib para fundo escuro
plt.style.use('dark_background')
sns.set_palette('GnBu_r')

# Carrega o dataset
df = pd.read_csv('/content/Dados-Grupo4.csv')

# Exibe o nÃºmero de linhas e colunas
print(f"Dataset possui {df.shape[0]} linhas e {df.shape[1]} colunas.")
```

<br><br>


## 5.2 - [InspeÃ§Ã£o inicial & limpeza]()

[***O que faz***](): `df.describe()`, remove `'Unnamed: 0'` se existir, preenche valores faltantes com a moda, remove duplicatas.

<br>

```python
print(df.describe())

# Remove coluna extra se existir
if 'Unnamed: 0' in df.columns:
    df = df.drop(columns=['Unnamed: 0'])

# Preenche valores faltantes
for col in df.columns:
    if df[col].isnull().any():
        df[col] = df[col].fillna(df[col].mode()[0])

# Remove duplicatas
df = df.drop_duplicates()
```

<br><br>


## 5.3 - [Escalonar features numÃ©ricas & scatter plot inicial]()

[***O que faz***](): padroniza as variÃ¡veis numÃ©ricas e gera o grÃ¡fico de dispersÃ£o inicial (tamanho 12Ã—8).

<br>

```python
from sklearn.preprocessing import StandardScaler

columns_to_scale = ['Coluna1', 'Coluna2']  # adapte se suas colunas forem diferentes
scaler = StandardScaler()
df_scaled = pd.DataFrame(scaler.fit_transform(df[columns_to_scale]), columns=columns_to_scale)

# --- PLOT 1: Scatter plot inicial ---
plt.figure(figsize=(12, 8))
sns.scatterplot(x=df_scaled['Coluna1'], y=df_scaled['Coluna2'])
plt.title('GrÃ¡fico de DispersÃ£o Inicial dos Dados Escalonados')
plt.xlabel('Coluna1 Escalonada')
plt.ylabel('Coluna2 Escalonada')
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()
```

<br>

### [***PLOT 1***]() â€” Scatter Inicial

<br>

<p align="center">
  <img src="https://github.com/user-attachments/assets/1f2d7894-6837-4f42-b689-2675e6e78cab" width="100%">
</p>


<br><br>

> [!TIP]
> 
> ğŸ‘ŒğŸ»
> 
> [***Para Salvar***](): add plt.savefig('initial_scatter.png', dpi=300, bbox_inches='tight') before de plt.show()
> 

<br><br>


## 5.4 - [GrÃ¡fico K-distance (determinar eps do DBSCAN)]()

[***O que faz***](): calcula a distÃ¢ncia para o 4Âº vizinho mais prÃ³ximo de cada ponto e plota as distÃ¢ncias ordenadas â€” o grÃ¡fico K-distance usado para escolher o valor de *eps*.

<br>

```python
from sklearn.neighbors import NearestNeighbors
import numpy as np

neigh = NearestNeighbors(n_neighbors=4)
neigh.fit(df_scaled)
distances, indices = neigh.kneighbors(df_scaled)
distances = np.sort(distances[:, 3], axis=0)  # distÃ¢ncia atÃ© o 4Âº vizinho

# --- PLOT 2: GrÃ¡fico K-distance ---
plt.figure(figsize=(12, 8))
plt.plot(distances)
plt.title('GrÃ¡fico K-distance para DBSCAN')
plt.xlabel('Pontos ordenados pela distÃ¢ncia')
plt.ylabel('Epsilon (DistÃ¢ncia)')
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()
```

<br>


### [***PLOT 2***]() - gerado por `plt.plot(distances)` + `plt.show()`.

Este grÃ¡fico Ã© essencial para escolher o valor de `eps` â€” procure o **â€œcotoveloâ€** (a curva onde hÃ¡ uma mudanÃ§a brusca).

<br>

<p align="center">
  <img src="https://github.com/user-attachments/assets/b680cc5c-8b24-4514-9bb0-5df6d56243da" width="100%">
</p>

<br><br>


> [!TIP]
> 
> ğŸ‘ŒğŸ»
> 
> [***Para Salvar***](): plt.savefig('k_distance.png', dpi=300, bbox_inches='tight').
>


<br><br>


## 5.5 - [Aplicar algoritmos de clusterizaÃ§Ã£o & visualizaÃ§Ã£o combinada]()

[***O que faz***](): executa K-Means, Mean-Shift e DBSCAN; armazena os rÃ³tulos (labels); plota os trÃªs resultados lado a lado.

<br>

```python
from sklearn.cluster import KMeans, MeanShift, DBSCAN
from sklearn.cluster import estimate_bandwidth

# K-Means
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
df_scaled['kmeans_labels'] = kmeans.fit_predict(df_scaled[['Coluna1','Coluna2']])

# Mean-Shift
bandwidth = estimate_bandwidth(df_scaled[['Coluna1', 'Coluna2']], quantile=0.2, n_samples=len(df_scaled))
meanshift = MeanShift(bandwidth=bandwidth, bin_seeding=True)
df_scaled['meanshift_labels'] = meanshift.fit_predict(df_scaled[['Coluna1','Coluna2']])

# DBSCAN (escolha eps pelo grÃ¡fico K-distance)
dbscan = DBSCAN(eps=0.25, min_samples=4)
df_scaled['dbscan_labels'] = dbscan.fit_predict(df_scaled[['Coluna1','Coluna2']])

# --- PLOT 3: ComparaÃ§Ã£o (trÃªs subplots) ---
plt.figure(figsize=(20, 7))

plt.subplot(1, 3, 1)
sns.scatterplot(x=df_scaled['Coluna1'], y=df_scaled['Coluna2'], hue=df_scaled['kmeans_labels'], palette='GnBu_r', legend='full')
plt.title('ClusterizaÃ§Ã£o K-Means (K=3)')
plt.grid(True, linestyle='--', alpha=0.7)

plt.subplot(1, 3, 2)
sns.scatterplot(x=df_scaled['Coluna1'], y=df_scaled['Coluna2'], hue=df_scaled['meanshift_labels'], palette='GnBu_r', legend='full')
plt.title(f'Mean-Shift (bandwidth={bandwidth:.2f})')
plt.grid(True, linestyle='--', alpha=0.7)

plt.subplot(1, 3, 3)
sns.scatterplot(x=df_scaled['Coluna1'], y=df_scaled['Coluna2'], hue=df_scaled['dbscan_labels'], palette='GnBu_r', legend='full')
plt.title('DBSCAN (eps=0.25, min_samples=4)')
plt.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()
```

<br>

### [***PLOT 3***]() - ComparaÃ§Ã£o:** a sequÃªncia `plt.subplot(...); sns.scatterplot(...); plt.show()` gera os trÃªs grÃ¡ficos juntos (K-Means, Mean-Shift, DBSCAN).

<br>

<p align="center">
  <img src="https://github.com/user-attachments/assets/79a7f744-7acc-46cd-9cb5-e7532051bb4d" width="100%">
</p>

<br><br>

> [!TIP]
> 
> ğŸ‘ŒğŸ»
> 
> [***Para Salvar***](): each subplot as a single image: before `plt.show()`, use `plt.savefig('comparison_three_algorithms.png', dpi=300, bbox_inches='tight')`.
>
> [***Para Salvar***](): separate images for each algorithm, move each subplot block into separate cells and save them individually.
>

<br><br>


## 5.6 - [Exibir contagem de clusters & mÃ©tricas opcionais]()

[***O que faz***](): mostra quantos clusters cada mÃ©todo encontrou e, opcionalmente, calcula o *silhouette score*.

<br>

```python
print(f"NÃºmero de clusters K-Means: {df_scaled['kmeans_labels'].nunique()}")
print(f"NÃºmero de clusters Mean-Shift: {df_scaled['meanshift_labels'].nunique()}")
print(f"NÃºmero de clusters DBSCAN (excluindo ruÃ­do -1): {df_scaled['dbscan_labels'].nunique() - (1 if -1 in df_scaled['dbscan_labels'].unique() else 0)}")

# Opcional: silhouette
from sklearn.metrics import silhouette_score
print('Silhouette K-Means:', silhouette_score(df_scaled[['Coluna1','Coluna2']], df_scaled['kmeans_labels']))
```

<br><br>


<br><br>

## 6. [Resumo dos resultados & interpretaÃ§Ã£o]()

* [**K-Means (K=3):**]() Encontrou 3 clusters â€” linha de base padrÃ£o, assume grupos arredondados.
* [**Mean-Shift:**]() Encontrou 4 clusters â€” se adapta automaticamente Ã s regiÃµes densas.
* [**DBSCAN**]() (eps escolhido pelo grÃ¡fico K-distance, min_samples=4): Encontrou 5 clusters + ruÃ­do â€” bom para grupos densos e detecÃ§Ã£o de outliers.
* [**InterpretaÃ§Ã£o:**]() Cada mÃ©todo agrupa os pontos de forma diferente, dependendo das regras. Ã‰ como organizar brinquedos por cor vs por proximidade na prateleira â€” os montes serÃ£o diferentes.

<br><br>


## 7. [PrÃ³ximos passos & sugestÃµes]()

[-]() Calcular mÃ©tricas como *silhouette score* ou Ã­ndice de Davies-Bouldin para comparar os mÃ©todos numericamente.

[-]() Testar outros valores de K para o K-Means; experimentar diferentes quantis para o *bandwidth* do Mean-Shift.

[-]() Com mais de 2 features, usar PCA/t-SNE/UMAP para visualizaÃ§Ã£o.

[-]() Se o DBSCAN encontrar muito ruÃ­do, ajustar *eps*/*min_samples* ou testar HDBSCAN.

[-]() Criar um slide comparando os trÃªs grÃ¡ficos lado a lado, com conclusÃµes em uma frase para cada.

[-]() Exemplo de cÃ³digo para *silhouette*:


<br>

```python
from sklearn.metrics import silhouette_score
print('KMeans silhouette:', silhouette_score(df_scaled, kmeans_labels))
```


<br><br>

## 8. [Requisitos & ambiente]()

[-]() Python 3.8 ou superior

[-]() pandas, numpy, matplotlib, seaborn, scikit-learn

[-]() Opcional: Jupyter Notebook ou Google Colab

<br><br>


<br><br>


## 9.  [Our Crew:]()


- ğŸ‘¨ğŸ½â€ğŸš€ **Andson Ribeiro** - [Slide into my inbox]()

- ğŸ‘©ğŸ»â€ğŸš€ **Fabiana âš¡ï¸ Campanari** - [Shoot me an email](mailto:fabicampanari@proton.me)

- ğŸ‘¨ğŸ½â€ğŸš€  **JosÃ© Augusto de Souza Oliveira**  - [email]()

- ğŸ§‘ğŸ¼â€ğŸš€ **Luan Fabiano**  - [email]()

- ğŸ‘¨ğŸ½â€ğŸš€ **Pedro Barrenco**  - [email]()
  
- ğŸ§‘ğŸ¼â€ğŸš€ **Pedro Vyctor** - [Hit me up by email](mailto:pedro.vyctor00@gmail.com)



<br><br>


<!-- ========================== [Bibliographry ====================  -->

<br><br>



<br><br>

## 10. [Bibliografia]()

[1](). **Castro, L. N. & Ferrari, D. G.** (2016). *IntroduÃ§Ã£o Ã  mineraÃ§Ã£o de dados: conceitos bÃ¡sicos, algoritmos e aplicaÃ§Ãµes*. Saraiva.

[2](). **Ester, M., Kriegel, H.-P., Sander, J., & Xu, X.** (1996). *A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise*.

[3](). **Ferreira, A. C. P. L. et al.** (2024). *InteligÃªncia Artificial â€” Uma Abordagem de Aprendizado de MÃ¡quina*. 2Âª Ed. LTC.

[4](). **Larson, R. & Farber, B.** (2015). *EstatÃ­stica Aplicada*. Pearson.

[5](). **MacQueen, J.** (1967). *Some Methods for Classification and Analysis of Multivariate Observations* â€” origem do K-Means.

[6](). **Meer, P. & Comaniciu, D.** (2002). *Mean Shift: A Robust Approach Toward Feature Space Analysis*.

[7](). **DocumentaÃ§Ã£o do scikit-learn** â€” algoritmos de clusterizaÃ§Ã£o.

[8](). **Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow** â€” referÃªncia geral de Data Science.



<br><br>


<!-- ======================================= Start Footer ===========================================  -->


<br><br>


## ğŸ’Œ [Let the data flow... Ping Me !](mailto:fabicampanari@proton.me)

<br><br>



#### <p align="center">  ğŸ›¸à¹‹ My Contacts [Hub](https://linktr.ee/fabianacampanari)


<br>

### <p align="center"> <img src="https://github.com/user-attachments/assets/517fc573-7607-4c5d-82a7-38383cc0537d" />




<br><br><br>

<p align="center">  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”­â‹† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


<p align="center"> â£â¢â¤ <a href="#top">Back to Top </a>

<!--
<p align="center">  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-->



<!-- Programmers and artists are the only professionals whose hobby is their profession."

" I love people who are committed to transforming the world "

" I'm big fan of those who are making waves in the world! "

##### <p align="center">( Rafael Lain ) </p>   -->

#

###### <p align="center"> Copyright 2025 Quantum Software Development. Code released under the [MIT License license.](https://github.com/Quantum-Software-Development/Math/blob/3bf8270ca09d3848f2bf22f9ac89368e52a2fb66/LICENSE)

















